:silent
    
// Compute a table of acceptance probabilities for smooth metropolis hastings testing. 
// Outputs a matrix "sigmaTable" in the current directory, which contains the probabilities. 
//
// The rows of sigmaTable are comprised:
//    sigma, xmin, xmax, accept(xmin, sigma), accept(xmin + deltaX, sigma) .... accept(xmax, sigma)
//
// where deltaX = (xmax - xmin)/(sigmaTable.nrows - 2)
//
// And where 
//   sigma is the standard deviation of the log probability ratio for a minibatch
//   x is the log probability ratio
//   xmin and xmax are the min and max values of x. 
//

// Resolution in sigma for the table. 
val nsigma = 280;

// Resolution of the table (half the number of columns). 
val n = 10000;

// Number of iterations to run for deconvolution.
val niter = 100000;

// Maximum x value, also negative of the minimum value.
val xmax = 40.0f;

// Learning rate for deconvolution.
val lrate = 200f;

// Range of sigma values for the table.
val sigmamin = 0.2;
val sigmamax = 3.0;

// Regularization constant (for L2 regularization) for backward gradient. 
val lambda = 1e-7;

// Another regularizer for backward filter (not currently used). 
val epsilon = 1f;

// When to print
val pstep = 10000;

// Space the sigma values out geometrically
val sigmas = sigmamin * exp(row(0->nsigma) * ln(sigmamax/sigmamin) / (nsigma-1));

// The table to save, and the accuracy for each row. 
val sigmaTable = dzeros(nsigma, 2*n+4);
val ebest = dzeros(nsigma, 1);

// Need to reduce the actual deconvolution gaussian sigma from the theoretical value. 
// This matrix contains correction factors. 
// The left column lists acceptance values. The right is a correction value c, such that
// actual sigma = c * predicted sigma. 

val sigSchedule = (
   0.05 \ 0.8 on
   0.1 \ 0.70 on 
   0.2 \ 0.68 on
   0.3 \ 0.66 on 
   0.4 \ 0.65 on
   0.5 \ 0.63 on 
   0.6 \ 0.61 on
   0.7 \ 0.58 on 
   0.8 \ 0.54 on
   0.9 \ 0.49 on 
   0.95 \ 0.4 );

// Look up the correction for a given acceptance value (interpolate the table above)
def sigCorrection(accept:Double) = { 
  var i = 0;
  while (i + 2 < sigSchedule.nrows && sigSchedule(i+1,0) < accept) { 
    i += 1;
  }
  val alpha = (accept - sigSchedule(i, 0)) / (sigSchedule(i+1,0) - sigSchedule(i, 0));
  alpha * sigSchedule(i+1, 1) + (1-alpha) * sigSchedule(i, 1);
}

// Compute the theoretical sigma at a given acceptance rate. Assumes the positive part of the graph is 
// a normal CDF. The actual sigma will be less than this by the correction above. 
def sigma0(accept:Double) = { 
  val xn = normcdfinv(drow(accept));
  (exp(-xn*xn/2) * math.sqrt(2 / scala.math.Pi) / accept).v;
}

// Invert the map from acceptance to sigma. Given a sigma value, use binary search to find
// the acceptance ratio. Includes the correction factor above. 
def acceptfn(sigma:Double) = { 
  val epsilon = 1e-8;
  var upper = 0.95;
  var lower = 0.05;
  var guess = 0.0;
  while (upper - lower > epsilon) { 
    guess = (upper+lower)/2;
    if (sigma0(guess) * sigCorrection(guess) < sigma) { 
      upper = guess;
    } else { 
      lower = guess;
    }
  }
  guess
}

// Normal range of x
val x = xmax / n * drow(-n to n);

// Wrapped range of x, used for FFT filters so they dont displace the input. 
val xf = xmax / n * (drow(0 to n) \ drow(-n until 0));

def distVariance(f:DMat, x:DMat) = {
    val meanv = (f dotr x) / sum(f);
    val meansq = ((x *@ x) dotr f) /sum(f);
    (meansq - meanv*meanv).v
    //    meansq - meanv *@ meanv;
};

// The original acceptance function.
def func1(q:Double, x:DMat) = exp(x/2) / ((2 * cosh(x * q / 2)) ^ (1f/q));

// Its derivative.
def deriv1(q:Double, x:DMat) = 0.5f*func1(q, x)*@(1f-tanh(q/2*x));

// The normal distribution used for deconvolution
def normfn(x:DMat, sigma:Double) = xmax*2/n/sqrt(2*scala.math.Pi * sigma) * exp(-x *@ x / (2 * sigma * sigma));

// Explicit complex multiply with "ZMats". ZMat doesnt exist, so use two rows of DMat. 
def cmult(a:DMat, b:DMat) = {
    (a(0,?) *@ b(0,?) - a(1,?) *@ b(1,?)) on
    (a(0,?) *@ b(1,?) + a(1,?) *@ b(0,?))
}

// Double complex FFT
def dofft(a:DMat, filter:DMat) = {
    val za = zfft(a on dzeros(1, a.length));
    val res = zifft(cmult(za, filter));
    res(0,?);
}

// Loop over sigma values (rows of the table)
for (isigma <- 0 until nsigma) { 

val sigma = sigmas(isigma);

val accept = acceptfn(sigma);

val sigma0 = sigma / sigCorrection(accept);

// alpha weights the CDF loss relative to the PDF loss.

val alpha0 = isigma * 1.0 / (nsigma-1);

val alpha = alpha0 * 30f + (1-alpha0) * 100f;

// Give acceptance rate, compute the p-norm in the base (pre-deconvolution) acceptance function.
// The acceptance function is 
//
//        exp(-x/2)/||exp(-x/2),exp(x/2)||^q
//
val q = -math.log(2)/math.log(accept);

var bestcumerr = 1.0;

// Target function, the PDF of the acceptance distribution.
val target = deriv1(q, x);

target ~ target / sum(target);

val tvar = distVariance(target, x);  // Actual variance of the distribution.

print("sigma=%5.4f, sigma0=%5.4f, accept = %6.5f" format (sigma, sigma0, accept))

val filter = normfn(xf, sigma);      // The filter centered at the ends of the vector.

val filterm = normfn(x, sigma);      // The filter centered in the vector.

val fwdfilter = zfft(filter on dzeros(1, filter.length)); // The FFT of the filter.

// Not currently used
val bwdfilter = dones(1, 2*n+1)/(fwdfilter + epsilon);

val vx = dzeros(1, 2*n+1);           // The log of the deconvolved density.

vx.set(-8f);

val density = exp(vx);

val preds = dzeros(1, 2*n+1);       // Placeholder for the convolution output.

val bestmodel = dzeros(1, 2*n+1);   // Holds the best model.
    
// Fwd function, exp(vx), then convolve with filter, take difference with target, mix with CDF loss.
def fwd() = {                       
    density <-- exp(vx);
    preds <-- dofft(density, fwdfilter);
    val diff = preds - target;
    diff + alpha / n * cumsum(diff);
}

// Well, The forward function has a strong identity term, and is otherwise very smooth. 
// Most true inverses or deconv functions for the backward step are extremely ill-conditioned and perform poorly. 
// So use this trivial approximation. 
def bwd() = {
    val c = fwd();
    (c + lambda);
};

// The main deconvolution iteration
var iter = 0;
while (iter <= niter) {
  val dvx = bwd();                               // Get a backward gradient.
  val diff = preds - target;                     // Get the prediction residual.
  val cumerr = maxi(abs(cumsum(diff))).v;        // Compute CDF error.
  if (cumerr < bestcumerr) {                     // If the error is lowest, update the best model and error. 
    bestcumerr = cumerr;
    bestmodel <-- vx;
  }
  vx ~ vx - (lrate * dvx);                       // Apply the derivative.
  if (iter % pstep == 0) {
    print(".");
  }
  iter += 1;
}

// Restore the best model
vx <-- bestmodel;
ebest(isigma) = bestcumerr;
fwd();
val diff = preds - target;
val cumerr = maxi(abs(cumsum(diff))).v;
val sharpness = (mean(density *@ density) / (mean(density) ^ 2)).v;
println(", err = %9.8f, cumerr = %7.6f, sharpness=%3.2f" format (maxi(abs(diff)).v, cumerr, sharpness));

sigmaTable(isigma, ?) = drow(sigma,-xmax,xmax) \ (cumsum(density) / sum(density));

}

:silent

saveDMat("sigmaN%d_M%d_v3_smooth.dmat.lz4" format (nsigma, n), sigmaTable);
